{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/kindeqi/.torch/models/vgg16-397923af.pth\n",
      "100%|██████████| 553433881/553433881 [00:09<00:00, 56679274.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\datasets\\\\pascal\\\\PASCAL_VOC\\\\pascal_train2007.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a62d540d7315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mSSD_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_SSD_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mVOC_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVOC_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdraw_img_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mSSDloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PyTorch_SSD/draw_img_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C:\\\\datasets\\\\pascal\\\\'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrn_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{PATH}PASCAL_VOC\\\\pascal_train2007.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mval_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{PATH}PASCAL_VOC\\\\pascal_val2007.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\datasets\\\\pascal\\\\PASCAL_VOC\\\\pascal_train2007.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.functional import F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib inline\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from fastai import transforms, model, dataset, conv_learner\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "from SSD_model import get_SSD_model\n",
    "from VOC_data import VOC_dataset\n",
    "from draw_img_utils import *\n",
    "from SSDloss import *\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "PATH = 'C:\\\\datasets\\\\pascal\\\\'\n",
    "anno_path = f'{PATH}PASCAL_VOC\\\\pascal_train2007.json'\n",
    "train_dataset = VOC_dataset(PATH, anno_path)\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "vgg_weight_path = '/home/kindeqi/.torch/models/vgg16-397923af.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_collate_fn(batch):\n",
    "    imgs, bboxes, labels = [], [], []\n",
    "    for i, b, l in batch:\n",
    "        imgs.append(i); bboxes.append(b); labels.append(l)\n",
    "    return torch.stack(imgs), bboxes, labels\n",
    "\n",
    "trn_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=detection_collate_fn)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "model = get_SSD_model(batch_size, vgg_weight_path)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "for i, batch in enumerate(trn_dataloader):\n",
    "    imgs, bboxes, labels = batch\n",
    "    imgs = imgs.to(device)\n",
    "    cls_preds, loc_preds = model(imgs)\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_loc_loss, total_cls_loss = 0, 0\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        \n",
    "        img, bbox, label = imgs[_], bboxes[_], labels[_]\n",
    "        cls_pred, loc_pred = cls_preds[_], loc_preds[_]\n",
    "\n",
    "        # img, bbox, label = tmp\n",
    "        # img, bbox, label = train_dataset[0]\n",
    "\n",
    "        # img = img.unsqueeze(0)\n",
    "\n",
    "        # cls_pred, loc_pred = model(img)\n",
    "        # cls_pred, loc_pred = cls_pred.squeeze(0), loc_pred.squeeze(0)\n",
    "\n",
    "        # PATH = 'C:\\\\datasets\\\\pascal\\\\'\n",
    "        # anno_path = f'{PATH}PASCAL_VOC\\\\pascal_train2007.json'\n",
    "        # train_dataset = VOC_dataset(PATH, anno_path)\n",
    "\n",
    "        # img, bbox, label = train_dataset[7]\n",
    "        # img = img.unsqueeze(0)\n",
    "\n",
    "        prior_box = get_prior_box()\n",
    "        iou = get_iou(bbox, prior_box)\n",
    "\n",
    "        pos_mask, cls_target, bbox_target = get_target(iou, prior_box, img, bbox, label)\n",
    "        pos_mask, cls_target, bbox_target = pos_mask.to(device), cls_target.to(device), bbox_target.to(device)\n",
    "\n",
    "        # model = get_SSD_model(1)\n",
    "        # cls_pred, loc_pred = model(img)\n",
    "        # cls_pred, loc_pred = cls_pred.squeeze(0), loc_pred.squeeze(0)\n",
    "\n",
    "        loss_loc, loss_cls = loss(cls_pred, loc_pred, pos_mask, cls_target, bbox_target)\n",
    "        total_loc_loss += loss_loc; total_cls_loss += loss_cls\n",
    "\n",
    "        total_loss += (loss_loc + loss_cls)\n",
    "\n",
    "    total_loss /= float(batch_size)\n",
    "    total_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    if i % 5 == 0:\n",
    "        print('cls_loss: {}, loc_loss: {}, loss: {}'.format(total_cls_loss / float(batch_size), total_loc_loss / float(batch_size), total_loss))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
