{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.functional import F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from fastai import transforms, model, dataset, conv_learner\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "from SSD_model import get_SSD_model\n",
    "from VOC_data import VOC_dataset\n",
    "from draw_img_utils import *\n",
    "from SSDloss import *\n",
    "\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "PATH = '/home/kindeqi/PyTorch_SSD/dataset/VOCdevkit/VOC2007'\n",
    "trn_anno_path = '/home/kindeqi/PyTorch_SSD/annotation/PASCAL_VOC/pascal_train2007.json'\n",
    "val_anno_path = '/home/kindeqi/PyTorch_SSD/annotation/PASCAL_VOC/pascal_val2007.json'\n",
    "\n",
    "train_dataset = VOC_dataset(PATH, trn_anno_path)\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "num_iter = 10\n",
    "vgg_weight_path = '/home/kindeqi/.torch/models/vgg16-397923af.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cls_loss: 3.025, loc_loss: 4.629, loss: 3.025\n",
      "10 cls_loss: 3.034, loc_loss: 4.447, loss: 3.034\n",
      "0 cls_loss: 2.75, loc_loss: 4.618, loss: 2.75\n",
      "10 cls_loss: 2.729, loc_loss: 4.431, loss: 2.729\n",
      "0 cls_loss: 2.539, loc_loss: 4.631, loss: 2.539\n",
      "10 cls_loss: 2.674, loc_loss: 4.43, loss: 2.674\n",
      "0 cls_loss: 2.409, loc_loss: 4.641, loss: 2.409\n",
      "10 cls_loss: 2.595, loc_loss: 4.43, loss: 2.595\n",
      "0 cls_loss: 2.404, loc_loss: 4.631, loss: 2.404\n",
      "10 cls_loss: 2.729, loc_loss: 4.429, loss: 2.729\n",
      "0 cls_loss: 2.475, loc_loss: 4.62, loss: 2.475\n",
      "10 cls_loss: 2.516, loc_loss: 4.433, loss: 2.516\n",
      "0 cls_loss: 2.418, loc_loss: 4.626, loss: 2.418\n",
      "10 cls_loss: 2.619, loc_loss: 4.432, loss: 2.619\n",
      "0 cls_loss: 2.363, loc_loss: 4.627, loss: 2.363\n",
      "10 cls_loss: 2.567, loc_loss: 4.432, loss: 2.567\n",
      "0 cls_loss: 2.372, loc_loss: 4.622, loss: 2.372\n",
      "10 cls_loss: 2.613, loc_loss: 4.432, loss: 2.613\n",
      "0 cls_loss: 2.457, loc_loss: 4.62, loss: 2.457\n",
      "10 cls_loss: 2.557, loc_loss: 4.431, loss: 2.557\n"
     ]
    }
   ],
   "source": [
    "def detection_collate_fn(batch):\n",
    "    imgs, bboxes, labels = [], [], []\n",
    "    for i, b, l in batch:\n",
    "        imgs.append(i); bboxes.append(b); labels.append(l)\n",
    "    return torch.stack(imgs), bboxes, labels\n",
    "\n",
    "trn_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=detection_collate_fn)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "model = get_SSD_model(batch_size, vgg_weight_path)\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer = torch.optim.SGD(params = model.parameters(), lr=1e-4, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for _ in range(num_iter):\n",
    "    \n",
    "    prior_box = get_prior_box()\n",
    "    \n",
    "    for i, batch in enumerate(trn_dataloader):\n",
    "        \n",
    "#         just the first 10 batch\n",
    "        if i >= 20:\n",
    "            continue\n",
    "        \n",
    "        imgs, bboxes, labels = batch\n",
    "        imgs = imgs.to(device)\n",
    "        cls_preds, loc_preds = model(imgs)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        total_loss = 0\n",
    "        total_loc_loss, total_cls_loss = 0, 0\n",
    "\n",
    "        for idx in range(imgs.shape[0]):\n",
    "\n",
    "            img, bbox, label = imgs[idx], bboxes[idx], labels[idx]\n",
    "            cls_pred, loc_pred = cls_preds[idx], loc_preds[idx]\n",
    "\n",
    "            # img, bbox, label = tmp\n",
    "            # img, bbox, label = train_dataset[0]\n",
    "\n",
    "            # img = img.unsqueeze(0)\n",
    "\n",
    "            # cls_pred, loc_pred = model(img)\n",
    "            # cls_pred, loc_pred = cls_pred.squeeze(0), loc_pred.squeeze(0)\n",
    "\n",
    "            # PATH = 'C:\\\\datasets\\\\pascal\\\\'\n",
    "            # anno_path = f'{PATH}PASCAL_VOC\\\\pascal_train2007.json'\n",
    "            # train_dataset = VOC_dataset(PATH, anno_path)\n",
    "\n",
    "            # img, bbox, label = train_dataset[7]\n",
    "            # img = img.unsqueeze(0)\n",
    "\n",
    "#             prior_box = get_prior_box()\n",
    "            iou = get_iou(bbox, prior_box)\n",
    "\n",
    "            pos_mask, cls_target, bbox_target = get_target(iou, prior_box, img, bbox, label)\n",
    "            pos_mask, cls_target, bbox_target = pos_mask.to(device), cls_target.to(device), bbox_target.to(device)\n",
    "\n",
    "            # model = get_SSD_model(1)\n",
    "            # cls_pred, loc_pred = model(img)\n",
    "            # cls_pred, loc_pred = cls_pred.squeeze(0), loc_pred.squeeze(0)\n",
    "\n",
    "            loss_loc, loss_cls = loss(cls_pred, loc_pred, pos_mask, cls_target, bbox_target)\n",
    "            total_loc_loss += loss_loc; total_cls_loss += loss_cls\n",
    "\n",
    "#             total_loss += (loss_loc + loss_cls)\n",
    "            total_loss += loss_cls\n",
    "\n",
    "        total_loss /= float(batch_size)\n",
    "        total_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            cls_loss = round(float(total_cls_loss / batch_size), 3)\n",
    "            loc_loss = round(float(total_loc_loss / batch_size), 3)\n",
    "            total_loss = round(float(total_loss), 3)\n",
    "            \n",
    "            print(i, 'cls_loss: {}, loc_loss: {}, loss: {}'.format(cls_loss, loc_loss, total_loss))\n",
    "        \n",
    "        if i == 20:\n",
    "            torch.save(model.state_dict(), '20.pth')\n",
    "        \n",
    "        if i == 50:\n",
    "            torch.save(model.state_dict(), '50.pth')\n",
    "            \n",
    "        if i == 100:\n",
    "            torch.save(model.state_dict(), '100.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bbox, label = train_dataset[11]\n",
    "img = img.unsqueeze(0).to(device)\n",
    "\n",
    "conf_pred, loc_pred = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_box = get_prior_box()\n",
    "iou = get_iou(bbox, prior_box)\n",
    "\n",
    "pos_mask, cls_target, bbox_target = get_target(iou, prior_box, img, bbox, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kindeqi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cls = F.softmax(conf_pred[0][pos_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.133, 0.143, 0.134, 0.145, 0.196, 0.125, 0.141, 0.221, 0.168, 0.189,\n",
       "         0.354, 0.206, 0.124, 0.109, 0.133, 0.123], device='cuda:0',\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([ 7,  7,  7,  7,  7,  7,  7,  7, 19, 15, 13, 19, 19, 19, 12, 19],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], dtype=torch.int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_target[pos_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_net[12].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_20 = get_SSD_model(1, vgg_weight_path)\n",
    "model_20.load_state_dict(torch.load('100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bbox, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred, loc_pred = model_20(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_box = get_prior_box()\n",
    "iou = get_iou(bbox, prior_box)\n",
    "\n",
    "pos_mask, cls_target, bbox_target = get_target(iou, prior_box, img, bbox, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cls_pred[0][pos_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7], dtype=torch.int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_target[pos_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kindeqi/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [7.446e-01, 3.591e-04, 1.342e-03, 1.275e-02, 2.664e-03, 1.323e-03,\n",
       "         1.368e-04, 1.786e-03, 2.293e-03, 6.282e-03, 1.915e-03, 1.188e-04,\n",
       "         2.109e-02, 6.637e-03, 1.521e-03, 1.833e-01, 2.602e-03, 6.436e-04,\n",
       "         2.065e-03, 1.601e-03, 4.908e-03],\n",
       "        [8.919e-01, 9.078e-04, 7.869e-03, 4.684e-03, 1.449e-03, 8.323e-04,\n",
       "         5.266e-04, 5.682e-03, 1.889e-03, 1.840e-03, 2.615e-03, 9.069e-04,\n",
       "         9.195e-03, 3.311e-03, 9.819e-04, 4.404e-02, 8.419e-04, 3.215e-04,\n",
       "         1.137e-02, 4.345e-03, 4.533e-03],\n",
       "        [9.790e-01, 2.614e-04, 1.240e-03, 1.517e-03, 2.369e-04, 2.168e-04,\n",
       "         5.880e-04, 1.532e-03, 2.478e-04, 1.299e-03, 9.068e-04, 3.366e-04,\n",
       "         9.254e-04, 8.900e-04, 5.745e-04, 5.490e-03, 3.667e-04, 2.010e-04,\n",
       "         1.881e-03, 1.448e-04, 2.192e-03],\n",
       "        [8.919e-01, 9.078e-04, 7.869e-03, 4.684e-03, 1.449e-03, 8.323e-04,\n",
       "         5.266e-04, 5.682e-03, 1.889e-03, 1.840e-03, 2.615e-03, 9.069e-04,\n",
       "         9.195e-03, 3.311e-03, 9.819e-04, 4.404e-02, 8.419e-04, 3.215e-04,\n",
       "         1.137e-02, 4.345e-03, 4.533e-03],\n",
       "        [7.423e-01, 6.901e-04, 1.484e-03, 4.642e-03, 3.937e-03, 1.021e-03,\n",
       "         6.685e-04, 4.262e-03, 5.574e-02, 9.642e-04, 2.658e-03, 7.006e-05,\n",
       "         2.842e-02, 3.027e-03, 1.104e-03, 1.345e-01, 2.298e-03, 5.491e-04,\n",
       "         2.030e-03, 6.576e-03, 3.074e-03],\n",
       "        [9.790e-01, 2.614e-04, 1.240e-03, 1.517e-03, 2.369e-04, 2.168e-04,\n",
       "         5.880e-04, 1.532e-03, 2.478e-04, 1.299e-03, 9.068e-04, 3.366e-04,\n",
       "         9.254e-04, 8.900e-04, 5.745e-04, 5.490e-03, 3.667e-04, 2.010e-04,\n",
       "         1.881e-03, 1.448e-04, 2.192e-03],\n",
       "        [8.919e-01, 9.078e-04, 7.869e-03, 4.684e-03, 1.449e-03, 8.323e-04,\n",
       "         5.266e-04, 5.682e-03, 1.889e-03, 1.840e-03, 2.615e-03, 9.069e-04,\n",
       "         9.195e-03, 3.311e-03, 9.819e-04, 4.404e-02, 8.419e-04, 3.215e-04,\n",
       "         1.137e-02, 4.345e-03, 4.533e-03],\n",
       "        [9.790e-01, 2.614e-04, 1.240e-03, 1.517e-03, 2.369e-04, 2.168e-04,\n",
       "         5.880e-04, 1.532e-03, 2.478e-04, 1.299e-03, 9.068e-04, 3.366e-04,\n",
       "         9.254e-04, 8.900e-04, 5.745e-04, 5.490e-03, 3.667e-04, 2.010e-04,\n",
       "         1.881e-03, 1.448e-04, 2.192e-03],\n",
       "        [8.919e-01, 9.078e-04, 7.869e-03, 4.684e-03, 1.449e-03, 8.323e-04,\n",
       "         5.266e-04, 5.682e-03, 1.889e-03, 1.840e-03, 2.615e-03, 9.069e-04,\n",
       "         9.195e-03, 3.311e-03, 9.819e-04, 4.404e-02, 8.419e-04, 3.215e-04,\n",
       "         1.137e-02, 4.345e-03, 4.533e-03],\n",
       "        [7.423e-01, 6.901e-04, 1.484e-03, 4.642e-03, 3.937e-03, 1.021e-03,\n",
       "         6.685e-04, 4.262e-03, 5.574e-02, 9.642e-04, 2.658e-03, 7.006e-05,\n",
       "         2.842e-02, 3.027e-03, 1.104e-03, 1.345e-01, 2.298e-03, 5.491e-04,\n",
       "         2.030e-03, 6.576e-03, 3.074e-03],\n",
       "        [8.919e-01, 9.078e-04, 7.869e-03, 4.684e-03, 1.449e-03, 8.323e-04,\n",
       "         5.266e-04, 5.682e-03, 1.889e-03, 1.840e-03, 2.615e-03, 9.069e-04,\n",
       "         9.195e-03, 3.311e-03, 9.819e-04, 4.404e-02, 8.419e-04, 3.215e-04,\n",
       "         1.137e-02, 4.345e-03, 4.533e-03],\n",
       "        [9.790e-01, 2.614e-04, 1.240e-03, 1.517e-03, 2.369e-04, 2.168e-04,\n",
       "         5.880e-04, 1.532e-03, 2.478e-04, 1.299e-03, 9.068e-04, 3.366e-04,\n",
       "         9.254e-04, 8.900e-04, 5.745e-04, 5.490e-03, 3.667e-04, 2.010e-04,\n",
       "         1.881e-03, 1.448e-04, 2.192e-03],\n",
       "        [8.919e-01, 9.078e-04, 7.869e-03, 4.684e-03, 1.449e-03, 8.323e-04,\n",
       "         5.266e-04, 5.682e-03, 1.889e-03, 1.840e-03, 2.615e-03, 9.069e-04,\n",
       "         9.195e-03, 3.311e-03, 9.819e-04, 4.404e-02, 8.419e-04, 3.215e-04,\n",
       "         1.137e-02, 4.345e-03, 4.533e-03],\n",
       "        [7.423e-01, 6.901e-04, 1.484e-03, 4.642e-03, 3.937e-03, 1.021e-03,\n",
       "         6.685e-04, 4.262e-03, 5.574e-02, 9.642e-04, 2.658e-03, 7.006e-05,\n",
       "         2.842e-02, 3.027e-03, 1.104e-03, 1.345e-01, 2.298e-03, 5.491e-04,\n",
       "         2.030e-03, 6.576e-03, 3.074e-03],\n",
       "        [7.611e-01, 4.186e-03, 5.286e-03, 1.921e-02, 9.602e-03, 3.258e-03,\n",
       "         2.994e-02, 1.391e-02, 1.483e-02, 5.032e-03, 9.974e-03, 9.030e-03,\n",
       "         1.479e-02, 5.482e-03, 6.156e-03, 3.279e-02, 4.356e-03, 1.442e-03,\n",
       "         1.874e-02, 2.371e-02, 7.141e-03],\n",
       "        [7.554e-01, 6.356e-03, 4.417e-03, 2.585e-02, 8.606e-03, 3.552e-03,\n",
       "         3.175e-02, 1.888e-02, 1.131e-02, 2.473e-03, 6.403e-03, 4.059e-03,\n",
       "         1.495e-02, 5.373e-03, 7.545e-03, 3.597e-02, 4.738e-03, 9.929e-03,\n",
       "         1.175e-02, 2.515e-02, 5.492e-03]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.767,  6.817,  1.074, -0.955],\n",
       "        [ 4.767,  7.649,  1.074, -0.955],\n",
       "        [ 4.767,  8.065,  1.074, -0.955],\n",
       "        [ 5.599,  3.072,  1.074, -0.955],\n",
       "        [ 5.599,  3.488,  1.074, -0.955],\n",
       "        [ 5.599,  4.320,  1.074, -0.955],\n",
       "        [ 6.431, -1.089,  1.074, -0.955],\n",
       "        [ 6.431, -0.257,  1.074, -0.955],\n",
       "        [ 6.431,  0.159,  1.074, -0.955],\n",
       "        [ 7.263, -4.834,  1.074, -0.955],\n",
       "        [ 7.263, -4.418,  1.074, -0.955],\n",
       "        [ 7.263, -3.585,  1.074, -0.955],\n",
       "        [ 7.263,  6.817,  1.074, -0.955],\n",
       "        [ 7.263,  7.649,  1.074, -0.955],\n",
       "        [ 7.263,  8.065,  1.074, -0.955],\n",
       "        [ 9.260,  1.992, -0.656,  0.781],\n",
       "        [11.186,  3.829,  0.289,  1.726],\n",
       "        [ 9.260,  3.169, -0.656,  0.781],\n",
       "        [ 9.623,  1.647, -0.464, -2.493],\n",
       "        [11.186, 13.075,  0.289,  1.726],\n",
       "        [ 9.260, 10.823, -0.656,  0.781],\n",
       "        [11.186, 14.497,  0.289,  1.726],\n",
       "        [ 9.260, 12.000, -0.656,  0.781],\n",
       "        [ 9.623,  6.235, -0.464, -2.493],\n",
       "        [ 9.848, -2.718, -0.656,  0.781],\n",
       "        [11.898, -1.861,  0.289,  1.726],\n",
       "        [ 9.848, -1.541, -0.656,  0.781],\n",
       "        [10.235, -0.801, -0.464, -2.493],\n",
       "        [ 9.127, -4.199, -1.602, -0.165],\n",
       "        [ 7.959, -3.662, -2.286, -0.849]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_target[pos_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 5.631e+00,  7.717e-01,  2.746e-01,  2.131e-03],\n",
       "        [ 9.183e+00,  1.652e+00,  7.651e-01,  9.103e-01],\n",
       "        [ 1.106e+01,  1.067e+00, -4.055e-01,  6.250e-01],\n",
       "        [ 9.183e+00,  1.652e+00,  7.651e-01,  9.103e-01],\n",
       "        [ 9.719e+00,  9.797e-01,  1.616e+00, -4.933e-01],\n",
       "        [ 1.106e+01,  1.067e+00, -4.055e-01,  6.250e-01],\n",
       "        [ 9.183e+00,  1.652e+00,  7.651e-01,  9.103e-01],\n",
       "        [ 1.106e+01,  1.067e+00, -4.055e-01,  6.250e-01],\n",
       "        [ 9.183e+00,  1.652e+00,  7.651e-01,  9.103e-01],\n",
       "        [ 9.719e+00,  9.797e-01,  1.616e+00, -4.933e-01],\n",
       "        [ 9.183e+00,  1.652e+00,  7.651e-01,  9.103e-01],\n",
       "        [ 1.106e+01,  1.067e+00, -4.055e-01,  6.250e-01],\n",
       "        [ 9.183e+00,  1.652e+00,  7.651e-01,  9.103e-01],\n",
       "        [ 9.719e+00,  9.797e-01,  1.616e+00, -4.933e-01],\n",
       "        [ 7.780e+00, -1.705e+00,  6.312e-01,  8.397e-01],\n",
       "        [ 6.641e+00, -2.375e+00,  5.100e-01,  9.978e-01]],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_pred[0][pos_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = slice(None, 20, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(s.start, s.stop):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
